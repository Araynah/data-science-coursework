geom_line() +
geom_vline(xintercept = ci94, col = "red",   linetype = "dashed") +
geom_vline(xintercept = ci98, col = "blue",  linetype = "dashed") +
geom_vline(xintercept = 32.5, col = "purple", size = 1) +
labs(title = "Sampling Distribution of Mean with 94% & 98% CIs",
x     = "Sample Mean",
y     = "Density") +
theme_minimal()
# simulate 10,000 sample‐means under H₀: μ = 34
null_means <- tibble(
stat = replicate(
n    = 10000,
expr = mean(rnorm(n = 50, mean = 34, sd = 8))
)
)
# now plot with ggplot
ggplot(null_means, aes(x = stat)) +
geom_histogram(binwidth = 0.2, fill = "gray80", color = "black") +
geom_vline(xintercept = 32.5, col = "blue", size = 1) +
labs(
title = "Null Distribution of Sample Mean (μ₀ = 34)",
x     = "Sample Mean",
y     = "Count"
) +
theme_minimal()
obs_mean <- 32.5
# two‐sided p-value
p_two <- mean(abs(null_means$stat - 34) >= abs(obs_mean - 34))
p_two
e <- 8 / sqrt(50)
# 94% CI
z94  <- qnorm(1 - 0.06/2)
ci94 <- 32.5 + c(-1,1) * z94 * se
# 98% CI
z98  <- qnorm(1 - 0.02/2)
ci98 <- 32.5 + c(-1,1) * z98 * se
ci94
ci98
shifted <- null_means %>%
mutate(stat_centered = stat - 34 + 32.5)
# 2) 94% CI → drop 3% tails
ci94 <- quantile(shifted$stat_centered, probs = c(0.03, 0.97))
# 3) 98% CI → drop 1% tails
ci98 <- quantile(shifted$stat_centered, probs = c(0.01, 0.99))
ci94
ci98
# density curve for N(32.5, se^2)
curve_df <- tibble(
x = seq(32.5 - 4*se, 32.5 + 4*se, length.out = 400),
y = dnorm(x, mean = 32.5, sd = se)
)
ggplot(curve_df, aes(x = x, y = y)) +
geom_line() +
geom_vline(xintercept = ci94, col = "red",   linetype = "dashed") +
geom_vline(xintercept = ci98, col = "blue",  linetype = "dashed") +
geom_vline(xintercept = 32.5, col = "purple", size = 1) +
labs(title = "Sampling Distribution of Mean with 94% & 98% CIs",
x     = "Sample Mean",
y     = "Density") +
theme_minimal()
# 1) Define standard error
se <- 8 / sqrt(50)
# 2) Compute z‐scores and CIs
z96  <- qnorm(1 - 0.04/2)   # for 96%
z98  <- qnorm(1 - 0.02/2)   # for 98%
ci96 <- 32.5 + c(-1,1) * z96 * se
ci98 <- 32.5 + c(-1,1) * z98 * se
# 3) Build a density curve for N(32.5, se^2)
curve_df <- tibble(
x = seq(32.5 - 4*se, 32.5 + 4*se, length.out = 400),
y = dnorm(x, mean = 32.5, sd = se)
)
# 4) Plot with vertical lines at the CI endpoints and the center
ggplot(curve_df, aes(x = x, y = y)) +
geom_line() +
geom_vline(xintercept = ci96, col = "red",   linetype = "dashed") +
geom_vline(xintercept = ci98, col = "blue",  linetype = "dashed") +
geom_vline(xintercept = 32.5, col = "purple", size = 1) +
labs(
title = "Sampling Distribution with 96% (red) & 98% (blue) CIs",
x     = "Sample Mean",
y     = "Density"
) +
theme_minimal()
# global chunk options
knitr::opts_chunk$set(echo = TRUE,
error = TRUE,
message = FALSE,
warning = FALSE,
comment = NA,
fig.width=6,
fig.height=5)
library(MASS)
library(tidyverse)
library(broom)
evals <- read.csv("evals-mod.csv")
evals <- evals %>%
rowwise() %>%
mutate(avg_bty = mean(bty_f1lower:bty_m2upper)) %>%
ungroup()
evals <- evals %>%
rowwise() %>%
mutate(avg_bty = mean(bty_f1lower:bty_m2upper)) %>%
ungroup()
evals
mod.fit <- lm(score ~ language, data = evals )
mod.fit %>%
broom::tidy()
ggplot(evals, aes(x= rank, y= score)) +
geom_jitter() +
labs(x = "Rank of Professor", y = "Course evaluation score")
mod.fit <- lm(score ~ rank, data = evals )
mod.fit %>%
broom::tidy()
evals <- evals %>%
mutate(rank_new = relevel(factor(rank), ref = "tenured"))
evals <- evals %>%
mutate(rank_new = relevel(factor(rank), ref = "tenured"))
evals
mod.fit <- lm(score ~ rank_new, data = evals )
mod.fit %>%
broom::tidy()
mod.fit <- lm(score ~ gender,rank,avg_bty, data = evals )
mod.fit %>%
broom::tidy()
mod.fit <- lm(score ~ gender+rank+avg_bty, data = evals )
mod.fit %>%
broom::tidy()
mod.fit <- lm(score ~ gender+rank+avg_bty, data = evals )
mod.fit %>%
broom::tidy()
mod_mult <- lm(score ~ gender + rank + avg_bty, data = evals)
tidy(mod_mult)
mod.fit <- lm(score ~ gender+rank+avg_bty, data = evals )
mod.fit %>%
broom::tidy()
glance(mod.fit) %>%
select(r.squared, adj.r.squared)
mod_mult <- lm(score ~ gender + rank + avg_bty, data = evals)
tidy(mod_mult)
library(MASS)
library(tidyverse)
library(broom)
glance(mod_mult) %>%
select(r.squared, adj.r.squared)
glance(mod_mult) %>%
select(r.squared, adj.r.squared)
glance(mod_mult) %>%
select(r.squared, adj.r.squared)
library(dplyr)   # make sure dplyr is loaded
glance(mod_mult) %>%
select(r.squared, adj.r.squared)
library(dplyr)   # make sure dplyr is loaded
glance(mod_mult) %>%
select(r.squared, adj.r.squared)
glance(mod_mult) %>%
dplyr::select(r.squared, adj.r.squared)
mod_simple <- lm(score ~ gender + avg_bty, data = evals)
glance(mod_simple) %>%
select(r.squared, adj.r.squared)
mod_simple <- lm(score ~ gender + avg_bty, data = evals)
glance(mod_simple) %>%
dplyr::select(r.squared, adj.r.squared)
mod_full <- lm(score ~ rank_new
+ ethnicity
+ gender
+ language
+ age
+ cls_perc_eval
+ cls_students
+ cls_level
+ cls_profs
+ cls_credits
+ avg_bty,
data = evals)
glance(mod_full) %>%
dplyr::select(r.squared, adj.r.squared)
best_mod <- stepAIC(mod_full, direction = "backward", trace = FALSE)
# final R²
glance(best_mod) %>%
select(r.squared, adj.r.squared)
# final R²
glance(best_mod) %>%
dyplr::select(r.squared, adj.r.squared)
# final R²
glance(best_mod) %>%
dplyr::select(r.squared, adj.r.squared)
new_prof <- tibble(
rank_new     = "tenured",
ethnicity    = "not minority",
gender       = "female",
language     = "English",
age          = 40,
cls_perc_eval= 75,
cls_students = 30,
cls_level    = "upper",
cls_profs    = "single",
cls_credits  = "multi credit",
avg_bty      = mean(evals$avg_bty)
)
new_prof <- tibble(
rank_new     = "tenured",
ethnicity    = "not minority",
gender       = "female",
language     = "English",
age          = 40,
cls_perc_eval= 75,
cls_students = 30,
cls_level    = "upper",
cls_profs    = "single",
cls_credits  = "multi credit",
avg_bty      = mean(evals$avg_bty)
)
new_prof
predict(best_mod, newdata = new_prof,
interval = "prediction", level = 0.95)
# global chunk options
knitr::opts_chunk$set(echo = TRUE,
error = TRUE,
message = FALSE,
warning = FALSE,
comment = NA,
fig.width=6,
fig.height=5)
# set seed
set.seed(3212019)
library(tidyverse)
library(caret)
library(gifski)
theme_custom <- function() {
theme_bw() +
theme(text = element_text(color = "#4C6A92"),
axis.title = element_text(size = 16),
title = element_text(size = 20),
legend.title = element_text(size = 10),
legend.text = element_text(size = 10),
axis.text.x = element_text(size = 12),
axis.text.y = element_text(size = 12),
plot.caption = element_text(size = 10))
}
theme_custom <- function() {
theme_bw() +
theme(text = element_text(color = "#4C6A92"),
axis.title = element_text(size = 16),
title = element_text(size = 20),
legend.title = element_text(size = 10),
legend.text = element_text(size = 10),
axis.text.x = element_text(size = 12),
axis.text.y = element_text(size = 12),
plot.caption = element_text(size = 10))
}
theme_custom <- function() {
theme_bw() +
theme(text = element_text(color = "#4C6A92"),
axis.title = element_text(size = 16),
title = element_text(size = 20),
legend.title = element_text(size = 10),
legend.text = element_text(size = 10),
axis.text.x = element_text(size = 12),
axis.text.y = element_text(size = 12),
plot.caption = element_text(size = 10))
}
# data url
wineurl <- paste("https://archive.ics.uci.edu/ml/",
"machine-learning-databases/wine/wine.data", sep = "")
# read in data and set as tibble
wine <- as_tibble(read.csv(file = 'wine.csv', header = TRUE))
# assign variable names
# colnames(wine) <- c("origin", "alcohol", "acid",
#                        "ash", "alcalinity", "magnesium",
#                        "phenols", "flavanoids", "nonflavanoid",
#                        "proanthocyanins","color.int", "hue",
#                        "od", "proline")
# change origin to factor
wine <- wine %>%
mutate(Wine = factor(Wine))
wine
for (i in names(wine)[-1]) {
print(
wine %>%
#select(origin, i) %>%
ggplot(mapping = aes(x = Wine, y = get(i))) +
geom_boxplot(fill = "#AD5D5D") +
labs(x = "origin", y = i) +
theme_custom()
)
}
ggplot(wine, aes(x= Flavanoids, y= Phenols, color=Wine, shape=Wine)) +
geom_point()
origin_count <- wine %>%
group_by(Wine) %>%
dplyr::count(Wine)
origin_count
sum(is.na(wine))
glimpse(wine)
train.index <- createDataPartition(wine$Wine, p=0.70, list=FALSE)
train.index
train.index <- createDataPartition(wine$Wine, p=0.70, list=FALSE)
train.index <- createDataPartition(wine$Wine, p=0.70, list=FALSE)
wine.train <- wine %>% slice(train.index)
wine.train
wine.test  <- wine %>% slice(-train.index)
wine.test
train.knn <- train(
origin ~ .,
method = "knn",
data   = train.transformed,
tuneLength = 10
)
train.proc <- preProcess(
wine.train,
method = c("center", "scale")
)
# Show the per‐feature means (for centering)
train.proc$mean
# Show the per‐feature standard deviations (for scaling)
train.proc$std
train.proc <- preProcess(
wine.train,
method = c("center", "scale")
)
# standardize training
train.transformed <- predict(train.proc, wine.train)
# standardize testing
test.transformed <- predict(train.proc, wine.test)
train.knn <- train(
origin ~ .,
method    = "knn",
data      = train.transformed,
tuneLength = 10
)
# Show the best‐tuning result
train.knn$bestTune
library(caret)
train.knn <- train(
origin ~ .,
method    = "knn",
data      = train.transformed,
tuneLength = 10
)
# Show the best‐tuning result
train.knn$bestTune
library(caret)
train.knn <- train(
origin ~ .,
data       = wine.train,
method     = "knn",
preProcess = c("center", "scale"),  # caret will center+scale automatically
tuneLength = 10
)
train.knn
library(caret)
# 1) build the preProcess object from your 70% training set
train.proc <- preProcess(wine.train, method = c("center","scale"))
# 2) apply it to get your standardized training and test sets
train.transformed <- predict(train.proc, newdata = wine.train)
test.transformed  <- predict(train.proc, newdata = wine.test)
set.seed(123)
train.knn <- train(
origin ~ .,
method    = "knn",
data      = train.transformed,   # now defined
tuneLength = 10
)
train.knn
library(caret)
# 1) build the preProcess object from your 70% training set
train.proc <- preProcess(wine.train, method = c("center","scale"))
# 2) apply it to get your standardized training and test sets
train.transformed <- predict(train.proc, newdata = wine.train)
test.transformed  <- predict(train.proc, newdata = wine.test)
set.seed(123)
train.knn <- train(
origin ~ .,
method    = "knn",
data      = train.transformed,   # now defined
tuneLength = 10
)
train.knn
library(caret)
# 1) build the preProcess object from your 70% training set
# train.knn on the standardized training set, predicting "Wine"
train.knn <- train(
Wine ~ .,
data       = train.transformed,
method     = "knn",
tuneLength = 10
)
train.knn
library(caret)
# train.knn on the standardized training set, predicting "Wine"
train.knn <- train(
Wine ~ .,
data       = train.transformed,
method     = "knn",
tuneLength = 10
)
train.knn
# plot accuracy for different k
train.knn %>%
ggplot(highlight = TRUE) +
theme_custom()
# expanded grid of k values
train.knn.big.grid <- train(form = origin ~ .,
method = "knn",
data = train.transformed,
tuneGrid = data.frame(k = seq(3, 39, 2)))
# plot accuracy for different k
train.knn.big.grid %>%
ggplot(highlight = TRUE) +
theme_custom()
ctrl <- trainControl(method = "boot", number = 25)
set.seed(123)
train.knn.big.grid <- train(
Wine ~ .,
method    = "knn",
data      = train.transformed,
trControl = ctrl,
tuneGrid  = data.frame(k = seq(3, 39, 2))
)
# Which k was best?
train.knn.big.grid$bestTune
# Plot accuracy vs. k
autoplot(train.knn.big.grid) +
theme_custom() +
labs(title = "K-NN Accuracy over k (3 to 39)",
x     = "Number of Neighbors (k)",
y     = "Accuracy")
ctrl <- trainControl(method = "boot", number = 25)
set.seed(123)
knn_results <- train.knn.big.grid$results
# Plot accuracy vs. k
ggplot(knn_results, aes(x = k, y = Accuracy)) +
geom_line() +
geom_point(size = 2) +
theme_custom() +
labs(
title = "K-NN Accuracy across Different k Values",
x     = "Number of Neighbors (k)",
y     = "Accuracy"
)
train.knn$bestTune
train.knn.big.grid$bestTune
y2.hat <- predict(train.knn.big.grid, newdata = test.transformed)
# Confusion matrix and overall accuracy
cm2 <- confusionMatrix(
data      = y2.hat,
reference = test.transformed$Wine
)
cm2
cm2$overall["Accuracy"]
y.hat <- predict(train.knn, test.transformed)
confusionMatrix(data = y.hat, reference = test.transformed$origin)
wine.test  <- wine %>% slice(-train.index)
wine.test
train.proc <- preProcess(
wine.train,
method = c("center", "scale")
)
# Show the per‐feature means (for centering)
train.proc$mean
# Show the per‐feature standard deviations (for scaling)
train.proc$std
# standardize training
train.transformed <- predict(train.proc, wine.train)
# standardize testing
test.transformed <- predict(train.proc, wine.test)
library(caret)
# train.knn on the standardized training set, predicting "Wine"
train.knn <- train(
Wine ~ .,
data       = train.transformed,
method     = "knn",
tuneLength = 10
)
train.knn
y.hat <- predict(train.knn, test.transformed)
confusionMatrix(data = y.hat, reference = test.transformed$origin)
y.hat <- predict(train.knn, test.transformed)
confusionMatrix(data = y.hat, reference = test.transformed$origin)
y.hat <- predict(train.knn, test.transformed)
confusionMatrix(data = y.hat, reference = test.transformed$origin)
y.hat <- predict(train.knn, test.transformed)
confusionMatrix(data = y.hat, reference = test.transformed$origin)
y.hat <- predict(train.knn, test.transformed)
confusionMatrix(data = y.hat, reference = test.transformed$origin)
# 1) Predict on the standardized test set
y.hat <- predict(train.knn, newdata = test.transformed)
# 2) Reference the correct column name "Wine"
ref   <- test.transformed$Wine
# 3) Make sure both are factors with identical levels
y.hat <- factor(y.hat, levels = levels(ref))
ref   <- factor(ref,   levels = levels(ref))
# 4) Compute confusion matrix
cm <- confusionMatrix(data      = y.hat,
reference = ref)
cm
# plot accuracy for different k
train.knn %>%
ggplot(highlight = TRUE) +
theme_custom()
# 1) Predict on the standardized test set
y.hat <- predict(train.knn, newdata = test.transformed)
# 2) Reference the correct column name "Wine"
ref   <- test.transformed$Wine
# 3) Make sure both are factors with identical levels
y.hat <- factor(y.hat, levels = levels(ref))
ref   <- factor(ref,   levels = levels(ref))
# 4) Compute confusion matrix
cm <- confusionMatrix(data      = y.hat,
reference = ref)
cm
